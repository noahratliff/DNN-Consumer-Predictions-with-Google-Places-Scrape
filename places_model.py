# -*- coding: utf-8 -*-
"""Places-Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RHYB5ogsFw0XF8oFMVc6pnWy6gTympsv
"""

from google.colab import drive
drive.mount('/content/gdrive')
from keras.models import Sequential
from keras.layers import Dense
!cp '/content/gdrive/My Drive/HIMCM 2019/google_places2.csv' input.csv

import pandas as pd
import nltk
import tflearn
import tensorflow
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
#Import scikit-learn metrics module for accuracy calculation
from sklearn import metrics
nltk.download('punkt')

df = pd.read_csv('input.csv')

words = []
cleanavg = df[np.isfinite(df['avg_time'])]

def tok(row):
  newrow = []
  for i in row:
    newrow.append(i)
  return(newrow) 

# print(nltk.word_tokenize('hello'))

for i in cleanavg['types']:
  wordbank = nltk.word_tokenize(i)
  for word in wordbank:
    if word not in words:
      words.append(word)

words.remove('[')
words.remove(']')
words.remove(',')
words.remove(r"'")
wrds = []
for i in words:
  wrds.append(i.replace(r"'",''))
# words = words.remove()
X = []
print(wrds)
for i in cleanavg['types']:
  wordbank = nltk.word_tokenize(i)
  bag = []
  for w in wrds:
      if w in i:
          bag.append(1)
      else:
          bag.append(0)
  X.append(bag)

# print(cleanavg['types'][0:1])

# cleanavg['types'] = cleanavg.apply(tok, axis=0)
# print(cleanavg['types'])
# print(cleanavg['types'][0:50])

y= np.array(cleanavg['avg_time'])
X= np.array(X)
out = cleanavg['avg_time']

times = []
y = []
for i in cleanavg['avg_time']:
  if i not in times:
    times.append(i)

for i in cleanavg['avg_time']:
  bag = []
  for t in times:
      if t == i:
          bag.append(1)
      else:
          bag.append(0)
  y.append(bag)

y = np.array(y)

print(len(X))
# print(np.array(y))

print(X.shape)

# y = X.reshape((8, len(X)))

trainX, testX, trainY, testY = train_test_split(X, y, test_size=0.33, random_state=42)

print(trainX.shape)
print(trainY.shape)

layer_count = [1,2,3]
node_count = [4,8,16,32, 64, 128, 256]
scores = []


for layers in layer_count:
  for nodes in node_count:
    tensorflow.reset_default_graph()
    net = tflearn.input_data(shape=[None, len(trainX[0])])
    for i in range(layers):
      net = tflearn.fully_connected(net, nodes)
    net = tflearn.fully_connected(net, len(trainY[0]), activation="softmax",)
    net = tflearn.regression(net)

    model = tflearn.DNN(net,tensorboard_verbose=3)

    model.fit(trainX, trainY, n_epoch=50, batch_size=8, show_metric=True)
    model.save("model.tflearn")

    scores.append(['layers-'+str(layers)+'nodes-'+str(nodes),model.evaluate(trainX,trainY),model.evaluate(testX,testY)])

print(scores)

!pip install tensorboardcolab
from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback

tbc=TensorBoardColab()
writer = tbc.get_writer() # To create a FileWriter
writer.add_graph(tensorflow.get_default_graph()) # add the graph 
writer.add_graph(tensorflow.get)
writer.flush()

def checkX(result):
  results = model.predict(result)
  results_index = np.argmax(results)
  return(times[results_index])

def checkY(result):
  results_index = np.argmax(result)
  return(times[results_index])

losses = 0
for x,y in zip(testX,testY):
  resx = (checkX(testX[[5]]))
  resy = (checkY(testY[[5]]))
  losses = losses + (np.abs(resx-resy))

print(losses/int(len(testX)))

counts = { i : 0 for i in types}
print(counts)
for i in cleanavg['types']:
  split = nltk.word_tokenize(i)
  print(split)
  for b in range(len(split)):
    for j in range(len(types)):
      if types[j] in split:
        counts[split] = counts[split] + 1

print(counts)

types = ['accounting',
'airport',
'amusement_park',
'aquarium',
'art_gallery',
'atm',
'bakery',
'bank',
'bar',
'beauty_salon',
'bicycle_store',
'book_store',
'bowling_alley',
'bus_station',
'cafe',
'campground',
'car_dealer',
'car_rental',
'car_repair',
'car_wash',
'casino',
'cemetery',
'church',
'city_hall',
'clothing_store',
'convenience_store',
'courthouse',
'dentist',
'department_store',
'doctor',
'drugstore',
'electrician',
'electronics_store',
'embassy',
'fire_station',
'florist',
'funeral_home',
'furniture_store',
'gas_station',
'grocery_or_supermarket',
'gym',
'hair_care',
'hardware_store',
'hindu_temple',
'home_goods_store',
'hospital',
'insurance_agency',
'jewelry_store',
'laundry',
'lawyer',
'library',
'light_rail_station',
'liquor_store',
'local_government_office',
'locksmith',
'lodging',
'meal_deli',
'meal_takeaway',
'mosque',
'movie_rental',
'movie_theater',
'moving_company',
'museum',
'night_club',
'painter',
'park',
'parking',
'pet_store',
'pharmacy',
'physiotherapist',
'plumber',
'police',
'post_office',
'primary_school',
'real_estate_agency',
'restaurant',
'roofing_contractor',
'rv_park',
'school',
'secondary_school',
'shoe_store',
'shopping_mall',
'spa',
'stadium',
'storage',
'store',
'subway_station',
'supermarket',
'synagogue',
'taxi_stand',
'tourist_attraction',
'train_station',
'transit_station',
'travel_agency',
'university',
'veterinary_care',
'zoo']